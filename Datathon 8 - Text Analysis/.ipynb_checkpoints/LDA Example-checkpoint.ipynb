{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA (Latent Dirichlet Allocation) Demo\n",
    "*Based on Jordan Barber's excellent LDA demo (https://goo.gl/XINIif)*\n",
    "\n",
    "You'll need to install the `gensim` package in order to perform the LDA. Open a command prompt or terminal and run:\n",
    "\n",
    "`conda install gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the text processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a tokenizer\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = nltk.stem.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some simple documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample documents\n",
    "doc_a = \"Broccoli is good to eat. My brother likes to eat good broccoli, but not my mother.\"\n",
    "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "doc_e = \"Health professionals say that broccoli is good for your health.\" \n",
    "\n",
    "# compile sample documents into a list\n",
    "doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize, clean, remove stopwords, and stem documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['broccoli', 'good', 'eat', 'brother', 'like', 'eat', 'good', 'broccoli', 'mother'], ['mother', 'spend', 'lot', 'time', 'drive', 'brother', 'around', 'basebal', 'practic'], ['health', 'expert', 'suggest', 'drive', 'may', 'caus', 'increas', 'tension', 'blood', 'pressur'], ['often', 'feel', 'pressur', 'perform', 'well', 'school', 'mother', 'never', 'seem', 'drive', 'brother', 'better'], ['health', 'profession', 'say', 'broccoli', 'good', 'health']]\n"
     ]
    }
   ],
   "source": [
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in doc_set:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "    \n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn our tokenized documents into a id <-> term dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(32 unique tokens: ['broccoli', 'brother', 'eat', 'good', 'like']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert tokenized documents into a document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 1), (2, 2), (3, 2), (4, 1), (5, 1)], [(1, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(8, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)], [(1, 1), (5, 1), (8, 1), (19, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)], [(0, 1), (3, 1), (16, 2), (30, 1), (31, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 3\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=num_topics, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what topics we found in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.031*\"profession\" + 0.031*\"say\" + 0.031*\"health\"'), (1, '0.074*\"drive\" + 0.072*\"health\" + 0.052*\"pressur\"'), (2, '0.149*\"broccoli\" + 0.149*\"good\" + 0.105*\"eat\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how topics map to some of our original texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.033614874), (1, 0.0345179), (2, 0.93186724)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel[dictionary.doc2bow(texts[0])] #doc_a = \"Broccoli is good to eat. My brother likes to eat good brocolli, but not my mother.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.026300361), (1, 0.94715315), (2, 0.026546443)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel[dictionary.doc2bow(texts[3])] #doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use this model to characterize new text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(new_string):\n",
    "    new_text_tokens = tokenizer.tokenize(new_string.lower())\n",
    "    new_stopped_tokens = [i for i in new_text_tokens if not i in en_stop]\n",
    "    new_stemmed_tokens = [p_stemmer.stem(i) for i in new_stopped_tokens]\n",
    "    return ldamodel[dictionary.doc2bow(new_stemmed_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.06767933), (1, 0.46175498), (2, 0.47056565)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topics(\"My mother and brother drive a broccoli truck.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing LDA results\n",
    "We can use the pyLDAvis package to inspect the results\n",
    "\n",
    "First, you'll need to install it from the command prompt/terminal. Anaconda doesn't index the package, so you'll need to use pip or another package manager (be sure to install for the right python version).\n",
    "\n",
    "`pip install pyldavis`\n",
    "\n",
    "You can play with some examples from larger sets of models here: http://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb#topic=0&lambda=1&term="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.031*\"profession\" + 0.031*\"say\" + 0.031*\"health\"'), (1, '0.074*\"drive\" + 0.072*\"health\" + 0.052*\"pressur\"'), (2, '0.149*\"broccoli\" + 0.149*\"good\" + 0.105*\"eat\"')]\n"
     ]
    }
   ],
   "source": [
    "# As a reminder, here are the topics we derived\n",
    "print(ldamodel.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el6613047007308566684862597\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el6613047007308566684862597_data = {\"mdsDat\": {\"Freq\": [70.47052764892578, 26.20207977294922, 3.3273961544036865], \"cluster\": [1, 1, 1], \"topics\": [1, 2, 3], \"x\": [-0.07532010393073785, 0.08968337555288754, -0.01436327162214968], \"y\": [0.0, 0.0, 0.0]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.3980445861816406, 2.3328030109405518, 1.678338885307312, 0.9587226510047913, 0.9587221145629883, 0.9587215781211853, 0.9587216377258301, 0.9587217569351196, 0.9587199687957764, 0.9587194323539734, 0.9587158560752869, 0.958465039730072, 0.9584574699401855, 0.9584472179412842, 0.9584458470344543, 0.9584345817565918, 0.9584327936172485, 0.9583830833435059, 0.9583815336227417, 0.9583814144134521, 0.9583808183670044, 0.9583814740180969, 0.9583784341812134, 0.9584270715713501, 1.675772786140442, 1.6757701635360718, 0.7721137404441833, 0.7719221115112305, 0.24001722037792206, 0.24001538753509521, 0.25124162435531616, 0.2512392997741699, 1.7960691452026367, 1.796069622039795, 1.2632380723953247, 0.7216840982437134, 0.7239752411842346, 0.7239735722541809, 0.32010912895202637, 0.31996870040893555, 0.18086840212345123, 0.1808651238679886, 0.18086369335651398, 0.18085607886314392, 0.1808544099330902, 0.18083953857421875, 0.18083828687667847, 0.18083824217319489, 0.1808377355337143, 0.180837482213974, 0.1808372288942337, 0.1808469146490097, 0.18084213137626648, 0.1807498335838318, 0.18074914813041687, 0.18074896931648254, 0.18074840307235718, 0.18074822425842285, 0.18074797093868256, 0.18074773252010345, 0.18074755370616913, 0.18082918226718903, 0.22918736934661865, 0.18083959817886353, 0.04773775488138199, 0.04810017719864845, 0.048099178820848465, 0.04783111810684204, 0.04783109575510025, 0.04783101752400398, 0.04783085361123085, 0.04783083498477936, 0.047830794006586075, 0.04781382158398628, 0.04781355708837509, 0.0478135384619236, 0.047813523560762405, 0.04781336337327957, 0.04781344532966614, 0.04781322181224823, 0.04778776317834854, 0.04778727516531944, 0.0477871336042881, 0.04778710752725601, 0.04778706654906273, 0.04778701066970825, 0.04778701066970825, 0.04778696224093437, 0.047734301537275314, 0.047792982310056686, 0.047803860157728195, 0.04780324175953865, 0.04787902161478996, 0.04787897691130638, 0.04799525439739227, 0.047799888998270035], \"Term\": [\"good\", \"broccoli\", \"eat\", \"like\", \"drive\", \"pressur\", \"mother\", \"brother\", \"practic\", \"time\", \"spend\", \"basebal\", \"lot\", \"around\", \"may\", \"caus\", \"suggest\", \"tension\", \"expert\", \"blood\", \"increas\", \"well\", \"seem\", \"perform\", \"school\", \"never\", \"feel\", \"often\", \"better\", \"health\", \"drive\", \"health\", \"pressur\", \"feel\", \"never\", \"perform\", \"often\", \"better\", \"school\", \"seem\", \"well\", \"caus\", \"may\", \"suggest\", \"tension\", \"blood\", \"increas\", \"lot\", \"time\", \"basebal\", \"practic\", \"around\", \"spend\", \"expert\", \"brother\", \"mother\", \"say\", \"profession\", \"like\", \"eat\", \"broccoli\", \"good\", \"good\", \"broccoli\", \"eat\", \"like\", \"mother\", \"brother\", \"profession\", \"say\", \"expert\", \"increas\", \"blood\", \"tension\", \"suggest\", \"spend\", \"around\", \"basebal\", \"practic\", \"time\", \"lot\", \"may\", \"caus\", \"well\", \"school\", \"seem\", \"better\", \"often\", \"perform\", \"never\", \"feel\", \"pressur\", \"health\", \"drive\", \"like\", \"profession\", \"say\", \"practic\", \"spend\", \"time\", \"basebal\", \"around\", \"lot\", \"expert\", \"blood\", \"increas\", \"suggest\", \"tension\", \"may\", \"caus\", \"well\", \"seem\", \"school\", \"perform\", \"never\", \"often\", \"feel\", \"better\", \"eat\", \"pressur\", \"good\", \"broccoli\", \"mother\", \"brother\", \"health\", \"drive\"], \"Total\": [2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.6266839504241943, 2.609985589981079, 1.9069610834121704, 1.1872572898864746, 1.187256932258606, 1.1872565746307373, 1.1872568130493164, 1.1872570514678955, 1.1872563362121582, 1.1872557401657104, 1.187253475189209, 1.1871203184127808, 1.1871178150177002, 1.18711519241333, 1.1871153116226196, 1.1871118545532227, 1.187111496925354, 1.1870511770248413, 1.1870501041412354, 1.187050461769104, 1.1870496273040771, 1.1870505809783936, 1.1870490312576294, 1.1871092319488525, 2.4476253986358643, 2.447624444961548, 1.1401816606521606, 1.1401314735412598, 1.0094391107559204, 1.550987720489502, 2.0951144695281982, 2.0951123237609863, 2.0951123237609863, 2.0951144695281982, 1.550987720489502, 1.0094391107559204, 2.447624444961548, 2.4476253986358643, 1.1401314735412598, 1.1401816606521606, 1.1871092319488525, 1.187111496925354, 1.1871118545532227, 1.1871153116226196, 1.18711519241333, 1.1870490312576294, 1.1870505809783936, 1.187050461769104, 1.1870496273040771, 1.1870501041412354, 1.1870511770248413, 1.1871178150177002, 1.1871203184127808, 1.187253475189209, 1.1872563362121582, 1.1872557401657104, 1.1872570514678955, 1.1872568130493164, 1.1872565746307373, 1.187256932258606, 1.1872572898864746, 1.9069610834121704, 2.609985589981079, 2.6266839504241943, 1.0094391107559204, 1.1401314735412598, 1.1401816606521606, 1.1870496273040771, 1.1870490312576294, 1.1870501041412354, 1.187050461769104, 1.1870505809783936, 1.1870511770248413, 1.1871092319488525, 1.1871118545532227, 1.187111496925354, 1.18711519241333, 1.1871153116226196, 1.1871178150177002, 1.1871203184127808, 1.187253475189209, 1.1872557401657104, 1.1872563362121582, 1.1872565746307373, 1.187256932258606, 1.1872568130493164, 1.1872572898864746, 1.1872570514678955, 1.550987720489502, 1.9069610834121704, 2.0951123237609863, 2.0951144695281982, 2.447624444961548, 2.4476253986358643, 2.609985589981079, 2.6266839504241943], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.258899986743927, 0.23770000040531158, 0.2222999930381775, 0.13619999587535858, 0.13619999587535858, 0.13619999587535858, 0.13619999587535858, 0.13619999587535858, 0.13619999587535858, 0.13619999587535858, 0.13619999587535858, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, 0.13600000739097595, -0.02889999933540821, -0.02889999933540821, -0.039799999445676804, -0.03999999910593033, -1.0865000486373901, -1.5160000324249268, -1.7710000276565552, -1.7710000276565552, 1.1852999925613403, 1.1852999925613403, 1.1340999603271484, 1.0038000345230103, 0.12120000272989273, 0.12120000272989273, 0.06909999996423721, 0.06859999895095825, -0.5422000288963318, -0.5422000288963318, -0.5422000288963318, -0.5422000288963318, -0.5422999858856201, -0.5422999858856201, -0.5422999858856201, -0.5422999858856201, -0.5422999858856201, -0.5422999858856201, -0.5422999858856201, -0.5422999858856201, -0.5422999858856201, -0.5429999828338623, -0.5429999828338623, -0.5429999828338623, -0.5429999828338623, -0.5429999828338623, -0.5429999828338623, -0.5429999828338623, -0.5429999828338623, -1.0163999795913696, -1.0931999683380127, -1.3365000486373901, 0.3515999913215637, 0.23739999532699585, 0.23729999363422394, 0.19140000641345978, 0.19140000641345978, 0.19140000641345978, 0.19140000641345978, 0.19140000641345978, 0.19140000641345978, 0.19099999964237213, 0.19099999964237213, 0.19099999964237213, 0.19099999964237213, 0.19099999964237213, 0.19099999964237213, 0.19099999964237213, 0.19040000438690186, 0.19030000269412994, 0.19030000269412994, 0.19030000269412994, 0.19030000269412994, 0.19030000269412994, 0.19030000269412994, 0.19030000269412994, -0.07800000160932541, -0.2833999991416931, -0.3772999942302704, -0.3772999942302704, -0.5311999917030334, -0.5311999917030334, -0.5929999947547913, -0.6035000085830688], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.6040000915527344, -2.6315999031066895, -2.960900068283081, -3.5208001136779785, -3.5208001136779785, -3.5208001136779785, -3.5208001136779785, -3.5208001136779785, -3.5208001136779785, -3.5208001136779785, -3.5208001136779785, -3.5211000442504883, -3.5211000442504883, -3.5211000442504883, -3.5211000442504883, -3.5211000442504883, -3.5211000442504883, -3.521199941635132, -3.521199941635132, -3.521199941635132, -3.521199941635132, -3.521199941635132, -3.521199941635132, -3.5211000442504883, -2.962399959564209, -2.962399959564209, -3.737299919128418, -3.737499952316284, -4.905700206756592, -4.905700206756592, -4.860000133514404, -4.860000133514404, -1.9036999940872192, -1.9036999940872192, -2.2555999755859375, -2.815500020980835, -2.812299966812134, -2.812299966812134, -3.6284000873565674, -3.6287999153137207, -4.1992998123168945, -4.1992998123168945, -4.1992998123168945, -4.199399948120117, -4.199399948120117, -4.19950008392334, -4.19950008392334, -4.19950008392334, -4.19950008392334, -4.19950008392334, -4.19950008392334, -4.199399948120117, -4.199399948120117, -4.199999809265137, -4.199999809265137, -4.199999809265137, -4.199999809265137, -4.199999809265137, -4.199999809265137, -4.199999809265137, -4.199999809265137, -4.19950008392334, -3.9625000953674316, -4.19950008392334, -3.4677000045776367, -3.460099935531616, -3.460200071334839, -3.4656999111175537, -3.4656999111175537, -3.4656999111175537, -3.4656999111175537, -3.4656999111175537, -3.4656999111175537, -3.466099977493286, -3.466099977493286, -3.466099977493286, -3.466099977493286, -3.466099977493286, -3.466099977493286, -3.466099977493286, -3.466599941253662, -3.4667000770568848, -3.4667000770568848, -3.4667000770568848, -3.4667000770568848, -3.4667000770568848, -3.4667000770568848, -3.4667000770568848, -3.4677999019622803, -3.4665000438690186, -3.4663000106811523, -3.4663000106811523, -3.4646999835968018, -3.4646999835968018, -3.4623000621795654, -3.466399908065796]}, \"token.table\": {\"Topic\": [1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [0.8424240946769714, 0.8424241542816162, 0.8422775864601135, 0.8423805832862854, 0.9546017646789551, 0.8171185255050659, 0.40855926275253296, 0.8423746228218079, 0.7614163160324097, 0.6447504162788391, 0.8423824906349182, 0.8422774076461792, 0.9546027779579163, 0.7662877440452576, 0.8423808813095093, 0.9906491637229919, 0.842423677444458, 0.8423763513565063, 0.8171188235282898, 0.4085594117641449, 0.8422776460647583, 0.8422777652740479, 0.8422779440879822, 0.842424750328064, 1.048789143562317, 0.8770918250083923, 0.8770532011985779, 0.8422780632972717, 0.8422785401344299, 0.8424251675605774, 0.8423782587051392, 0.8423781394958496, 0.8424244523048401, 0.8422801494598389], \"Term\": [\"around\", \"basebal\", \"better\", \"blood\", \"broccoli\", \"brother\", \"brother\", \"caus\", \"drive\", \"eat\", \"expert\", \"feel\", \"good\", \"health\", \"increas\", \"like\", \"lot\", \"may\", \"mother\", \"mother\", \"never\", \"often\", \"perform\", \"practic\", \"pressur\", \"profession\", \"say\", \"school\", \"seem\", \"spend\", \"suggest\", \"tension\", \"time\", \"well\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el6613047007308566684862597\", ldavis_el6613047007308566684862597_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el6613047007308566684862597\", ldavis_el6613047007308566684862597_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el6613047007308566684862597\", ldavis_el6613047007308566684862597_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Twitter Data\n",
    "\n",
    "Now let's try it with the data from our twitter corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet-id</th>\n",
       "      <th>tweet-text</th>\n",
       "      <th>tweet-author</th>\n",
       "      <th>tweet-timestamp</th>\n",
       "      <th>tweet-timestamp-date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Astrophysics is my first love, but I do occasi...</td>\n",
       "      <td>Neil deGrasse Tyson</td>\n",
       "      <td>1.477279e+12</td>\n",
       "      <td>10/24/16 3:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>JUST POSTED: @StarTalkRadio “Physics &amp; Fantasy...</td>\n",
       "      <td>Neil deGrasse Tyson</td>\n",
       "      <td>1.480000e+12</td>\n",
       "      <td>10/22/16 3:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>A reminder that in a baseball game you cannot ...</td>\n",
       "      <td>Neil deGrasse Tyson</td>\n",
       "      <td>1.477092e+12</td>\n",
       "      <td>10/21/16 23:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>The physics of Light Sabers: A brief argument ...</td>\n",
       "      <td>Neil deGrasse Tyson</td>\n",
       "      <td>1.480000e+12</td>\n",
       "      <td>10/17/16 20:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Full Moon this eve, across all Earth's lands. ...</td>\n",
       "      <td>Neil deGrasse Tyson</td>\n",
       "      <td>1.480000e+12</td>\n",
       "      <td>10/15/16 23:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>If a Space Alien landed in the USA &amp; requested...</td>\n",
       "      <td>Neil deGrasse Tyson</td>\n",
       "      <td>1.480000e+12</td>\n",
       "      <td>10/14/16 15:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Future headlines from the Multiverse: Nov 9, 2...</td>\n",
       "      <td>Neil deGrasse Tyson</td>\n",
       "      <td>1.480000e+12</td>\n",
       "      <td>10/9/16 14:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Awww. That’s the nicest thing anybody has said...</td>\n",
       "      <td>Neil deGrasse Tyson</td>\n",
       "      <td>1.480000e+12</td>\n",
       "      <td>10/7/16 17:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>If ComicCon people ruled the world, internatio...</td>\n",
       "      <td>Neil deGrasse Tyson</td>\n",
       "      <td>1.480000e+12</td>\n",
       "      <td>10/6/16 17:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>On Pluto, with its 248-year orbit around the S...</td>\n",
       "      <td>Neil deGrasse Tyson</td>\n",
       "      <td>1.475708e+12</td>\n",
       "      <td>10/5/16 23:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet-id                                         tweet-text  \\\n",
       "0       1.0  Astrophysics is my first love, but I do occasi...   \n",
       "1       2.0  JUST POSTED: @StarTalkRadio “Physics & Fantasy...   \n",
       "2       3.0  A reminder that in a baseball game you cannot ...   \n",
       "3       4.0  The physics of Light Sabers: A brief argument ...   \n",
       "4       5.0  Full Moon this eve, across all Earth's lands. ...   \n",
       "5       6.0  If a Space Alien landed in the USA & requested...   \n",
       "6       7.0  Future headlines from the Multiverse: Nov 9, 2...   \n",
       "7       8.0  Awww. That’s the nicest thing anybody has said...   \n",
       "8       9.0  If ComicCon people ruled the world, internatio...   \n",
       "9      10.0  On Pluto, with its 248-year orbit around the S...   \n",
       "\n",
       "          tweet-author  tweet-timestamp tweet-timestamp-date  \n",
       "0  Neil deGrasse Tyson     1.477279e+12        10/24/16 3:10  \n",
       "1  Neil deGrasse Tyson     1.480000e+12        10/22/16 3:21  \n",
       "2  Neil deGrasse Tyson     1.477092e+12       10/21/16 23:20  \n",
       "3  Neil deGrasse Tyson     1.480000e+12       10/17/16 20:38  \n",
       "4  Neil deGrasse Tyson     1.480000e+12       10/15/16 23:10  \n",
       "5  Neil deGrasse Tyson     1.480000e+12       10/14/16 15:49  \n",
       "6  Neil deGrasse Tyson     1.480000e+12        10/9/16 14:53  \n",
       "7  Neil deGrasse Tyson     1.480000e+12        10/7/16 17:20  \n",
       "8  Neil deGrasse Tyson     1.480000e+12        10/6/16 17:54  \n",
       "9  Neil deGrasse Tyson     1.475708e+12        10/5/16 23:00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"V&A Qualitative Datathon - Twitter @neiltyson - Raw_Data.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_set = df['tweet-text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter stop words\n",
    "twitter_stop = [\"twitter\",\"com\",\"pic\",\"http\",\"https\",\"www\",\"status\",\"bit\",\"ly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for tokenized documents in loop\n",
    "tweet_texts = []\n",
    "\n",
    "# preprocessing – clean, tokenize, remove stopwords, and stem\n",
    "for i in tweets_set:\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [t for t in tokens if (t not in en_stop and t not in twitter_stop)]\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    tweet_texts.append(stemmed_tokens)\n",
    " \n",
    "# build our dictionary and matrix\n",
    "tweet_dict = gensim.corpora.Dictionary(tweet_texts)\n",
    "tweet_corpus = [tweet_dict.doc2bow(text) for text in tweet_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['astrophys', 'first', 'love', 'occasion', 'give', 'schist', 'geolog'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'physic',\n",
       "  'fantasi',\n",
       "  'time',\n",
       "  'travel',\n",
       "  'w',\n",
       "  'michiokaku',\n",
       "  'itunespodcast',\n",
       "  '2eq226v'],\n",
       " ['remind',\n",
       "  'basebal',\n",
       "  'game',\n",
       "  'cannot',\n",
       "  'blame',\n",
       "  'umpir',\n",
       "  'enlarg',\n",
       "  'strike',\n",
       "  'zone',\n",
       "  'expand',\n",
       "  'univers'],\n",
       " ['physic',\n",
       "  'light',\n",
       "  'saber',\n",
       "  'brief',\n",
       "  'argument',\n",
       "  'profbriancox',\n",
       "  'lose',\n",
       "  'natgeo',\n",
       "  '2de7ooz'],\n",
       " ['full',\n",
       "  'moon',\n",
       "  'eve',\n",
       "  'across',\n",
       "  'earth',\n",
       "  'land',\n",
       "  'rise',\n",
       "  'gentli',\n",
       "  'east',\n",
       "  'curtain',\n",
       "  'twilight',\n",
       "  'descend'],\n",
       " ['space',\n",
       "  'alien',\n",
       "  'land',\n",
       "  'usa',\n",
       "  'request',\n",
       "  'take',\n",
       "  'leader',\n",
       "  'wonder',\n",
       "  'pre',\n",
       "  'trump',\n",
       "  'would',\n",
       "  'react',\n",
       "  'vs',\n",
       "  'pre',\n",
       "  'clinton'],\n",
       " ['futur',\n",
       "  'headlin',\n",
       "  'multivers',\n",
       "  'nov',\n",
       "  '9',\n",
       "  '2016',\n",
       "  'trump',\n",
       "  'got',\n",
       "  'hillari',\n",
       "  'elect',\n",
       "  'dismantl',\n",
       "  'republican',\n",
       "  'parti'],\n",
       " ['awww',\n",
       "  'nicest',\n",
       "  'thing',\n",
       "  'anybodi',\n",
       "  'said',\n",
       "  'long',\n",
       "  'ayeshatron',\n",
       "  '784441432652320769'],\n",
       " ['comiccon',\n",
       "  'peopl',\n",
       "  'rule',\n",
       "  'world',\n",
       "  'intern',\n",
       "  'conflict',\n",
       "  'would',\n",
       "  'resolv',\n",
       "  'entir',\n",
       "  'plastic',\n",
       "  'light',\n",
       "  'saber',\n",
       "  'fight',\n",
       "  'bar'],\n",
       " ['pluto',\n",
       "  '248',\n",
       "  'year',\n",
       "  'orbit',\n",
       "  'around',\n",
       "  'sun',\n",
       "  'birthday',\n",
       "  'incompat',\n",
       "  'human',\n",
       "  'physiolog'],\n",
       " ['anybodi', 'ask', 'mercuri', '240', 'year', 'old', 'saturn', '2'],\n",
       " ['thank',\n",
       "  'twittervers',\n",
       "  'birthday',\n",
       "  'wish',\n",
       "  'today',\n",
       "  'especi',\n",
       "  'feel',\n",
       "  'day',\n",
       "  '58'],\n",
       " ['urg',\n",
       "  'want',\n",
       "  'inform',\n",
       "  'true',\n",
       "  'often',\n",
       "  'cloud',\n",
       "  'abil',\n",
       "  'assess',\n",
       "  'inform',\n",
       "  'may',\n",
       "  'fals'],\n",
       " ['evid',\n",
       "  'internet',\n",
       "  'cat',\n",
       "  'rapidli',\n",
       "  'achiev',\n",
       "  'cosmic',\n",
       "  'conscious',\n",
       "  'soon',\n",
       "  'becom',\n",
       "  'overlord',\n",
       "  'youtub',\n",
       "  'watch',\n",
       "  'v',\n",
       "  'ljsh6ru1xrk',\n",
       "  'featur',\n",
       "  'share'],\n",
       " ['word', 'time', 'delus', 'sure', 'someth', 'true', 'face', 'evid', 'say'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'cosmic',\n",
       "  'queri',\n",
       "  'space',\n",
       "  'race',\n",
       "  'w',\n",
       "  'chucknicecom',\n",
       "  'itunespodcast',\n",
       "  'andhttp',\n",
       "  '2d4bfoz'],\n",
       " ['odd',\n",
       "  'measur',\n",
       "  'anim',\n",
       "  'intellig',\n",
       "  'often',\n",
       "  'test',\n",
       "  'human',\n",
       "  'best',\n",
       "  'rather',\n",
       "  'best'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'convers',\n",
       "  'ray',\n",
       "  'kurzweil',\n",
       "  'kurzweilainew',\n",
       "  'itunespodcast',\n",
       "  '2c6ufw6'],\n",
       " ['5',\n",
       "  'billion',\n",
       "  'yr',\n",
       "  'sun',\n",
       "  'expand',\n",
       "  'engulf',\n",
       "  'orbit',\n",
       "  'char',\n",
       "  'ember',\n",
       "  'earth',\n",
       "  'vapor',\n",
       "  'nice',\n",
       "  'day'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'extend',\n",
       "  'classic',\n",
       "  'cosmic',\n",
       "  'queri',\n",
       "  'superhero',\n",
       "  'w',\n",
       "  'colinjost',\n",
       "  'itun',\n",
       "  '2bqovxl'],\n",
       " ['interest',\n",
       "  'reflect',\n",
       "  'art',\n",
       "  'educ',\n",
       "  'david',\n",
       "  'byrn',\n",
       "  'video',\n",
       "  '3m',\n",
       "  '45',\n",
       "  'channel',\n",
       "  'nationalgeograph',\n",
       "  'startalk',\n",
       "  'video',\n",
       "  'import',\n",
       "  'art',\n",
       "  'educ'],\n",
       " ['object',\n",
       "  'truth',\n",
       "  'establish',\n",
       "  'evid',\n",
       "  'person',\n",
       "  'truth',\n",
       "  'faith',\n",
       "  'polit',\n",
       "  'truth',\n",
       "  'incess',\n",
       "  'repetit'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'cosmic',\n",
       "  'queri',\n",
       "  'random',\n",
       "  'edit',\n",
       "  'w',\n",
       "  'chucknicecom',\n",
       "  'itunespodcast',\n",
       "  '2bknqzj'],\n",
       " ['could',\n",
       "  'use',\n",
       "  'new',\n",
       "  'ballot',\n",
       "  'choic',\n",
       "  'none',\n",
       "  'beat',\n",
       "  'lead',\n",
       "  'candid',\n",
       "  'new',\n",
       "  'peopl',\n",
       "  'must',\n",
       "  'run',\n",
       "  'offic'],\n",
       " ['sens',\n",
       "  'think',\n",
       "  'enough',\n",
       "  'much',\n",
       "  'collect',\n",
       "  'yet',\n",
       "  'unwittingli',\n",
       "  'forc',\n",
       "  'politician',\n",
       "  'lie',\n",
       "  'us'],\n",
       " ['need',\n",
       "  'know',\n",
       "  'next',\n",
       "  'year',\n",
       "  'total',\n",
       "  'solar',\n",
       "  'eclips',\n",
       "  'across',\n",
       "  'usa',\n",
       "  'hayden',\n",
       "  'joerao12',\n",
       "  'space',\n",
       "  '33798',\n",
       "  'great',\n",
       "  'american',\n",
       "  'solar',\n",
       "  'eclips',\n",
       "  'one',\n",
       "  'year',\n",
       "  'away',\n",
       "  'html'],\n",
       " ['moon',\n",
       "  'shadow',\n",
       "  'landfal',\n",
       "  'oregon',\n",
       "  'cross',\n",
       "  'usa',\n",
       "  '1800mph',\n",
       "  'exit',\n",
       "  'scarolina',\n",
       "  'behold',\n",
       "  'muuurica',\n",
       "  'eclips',\n",
       "  'fimcneyyqi'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'cosmic',\n",
       "  'queri',\n",
       "  'multivers',\n",
       "  'w',\n",
       "  'paul',\n",
       "  'steinhardt',\n",
       "  'itunespodcast',\n",
       "  '2bdg569'],\n",
       " ['forg',\n",
       "  'atom',\n",
       "  'atom',\n",
       "  'via',\n",
       "  'thermonuclear',\n",
       "  'fusion',\n",
       "  'explos',\n",
       "  'remain',\n",
       "  'high',\n",
       "  'mass',\n",
       "  'star',\n",
       "  'thatsgold'],\n",
       " ['highli',\n",
       "  'non',\n",
       "  'chemic',\n",
       "  'reactiv',\n",
       "  'would',\n",
       "  'last',\n",
       "  'billion',\n",
       "  'year',\n",
       "  'space',\n",
       "  'thatsgold'],\n",
       " ['pure',\n",
       "  'form',\n",
       "  'soft',\n",
       "  'enough',\n",
       "  'bite',\n",
       "  'leav',\n",
       "  'teeth',\n",
       "  'mark',\n",
       "  'peopl',\n",
       "  'verifi',\n",
       "  'authent',\n",
       "  'coin',\n",
       "  'thatsgold'],\n",
       " ['unequal',\n",
       "  'reflector',\n",
       "  'infrar',\n",
       "  'light',\n",
       "  'coat',\n",
       "  'choic',\n",
       "  'nasa',\n",
       "  'jame',\n",
       "  'web',\n",
       "  'space',\n",
       "  'telescop',\n",
       "  'thatsgold'],\n",
       " ['extraordinari',\n",
       "  'conductor',\n",
       "  'excel',\n",
       "  'surfac',\n",
       "  'electr',\n",
       "  'contact',\n",
       "  'thatsgold'],\n",
       " ['300',\n",
       "  'metric',\n",
       "  'ton',\n",
       "  'embed',\n",
       "  'everi',\n",
       "  '500',\n",
       "  'meter',\n",
       "  'metal',\n",
       "  'asteroid',\n",
       "  'orbit',\n",
       "  'sun',\n",
       "  'thatsgold'],\n",
       " ['malleabl',\n",
       "  'hammer',\n",
       "  'cubic',\n",
       "  'foot',\n",
       "  'stuff',\n",
       "  'sheet',\n",
       "  'larg',\n",
       "  'enough',\n",
       "  'gild',\n",
       "  'rio',\n",
       "  'olymp',\n",
       "  'stadium',\n",
       "  'thatsgold'],\n",
       " ['nearli',\n",
       "  'twice',\n",
       "  'dens',\n",
       "  'lead',\n",
       "  'one',\n",
       "  'cubic',\n",
       "  'foot',\n",
       "  'weigh',\n",
       "  '1',\n",
       "  '200',\n",
       "  'pound',\n",
       "  'thatsgold'],\n",
       " ['effect',\n",
       "  'advertis',\n",
       "  'sister',\n",
       "  'bought',\n",
       "  'dodg',\n",
       "  'truck',\n",
       "  'step',\n",
       "  'insid',\n",
       "  'voic',\n",
       "  'drop',\n",
       "  'entir',\n",
       "  'octav'],\n",
       " ['want',\n",
       "  'see',\n",
       "  'tv',\n",
       "  'commerci',\n",
       "  'truck',\n",
       "  'announc',\n",
       "  'high',\n",
       "  'pitch',\n",
       "  'voic'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'convers',\n",
       "  'iamqueenlatifah',\n",
       "  'itunespodcast',\n",
       "  'andhttp',\n",
       "  '29n3gcu'],\n",
       " ['100',\n",
       "  '000',\n",
       "  'meter',\n",
       "  'per',\n",
       "  'sec',\n",
       "  'lightn',\n",
       "  'bolt',\n",
       "  '13',\n",
       "  '4',\n",
       "  'meter',\n",
       "  'per',\n",
       "  'sec',\n",
       "  'bolt',\n",
       "  '10',\n",
       "  '4',\n",
       "  'meter',\n",
       "  'per',\n",
       "  'sec',\n",
       "  'usain',\n",
       "  'boltpic',\n",
       "  'a01mwciih'],\n",
       " ['interest',\n",
       "  'larri',\n",
       "  'kingsth',\n",
       "  'ask',\n",
       "  'afterlif',\n",
       "  'video',\n",
       "  '7m',\n",
       "  'youtub',\n",
       "  'watch',\n",
       "  'v',\n",
       "  'ndj5kjkyr3'],\n",
       " ['set',\n",
       "  'world',\n",
       "  'record',\n",
       "  'olymp',\n",
       "  'might',\n",
       "  'classi',\n",
       "  'gave',\n",
       "  'platinum',\n",
       "  'medal',\n",
       "  'instead',\n",
       "  'gold'],\n",
       " ['usa',\n",
       "  '3x',\n",
       "  'mani',\n",
       "  'olymp',\n",
       "  'gold',\n",
       "  'hungari',\n",
       "  '30x',\n",
       "  'popul',\n",
       "  'adjust',\n",
       "  'hungari',\n",
       "  'kick',\n",
       "  'ass'],\n",
       " ['much',\n",
       "  'enthusiasm',\n",
       "  '2nd',\n",
       "  'amend',\n",
       "  'usa',\n",
       "  'least',\n",
       "  'expect',\n",
       "  'win',\n",
       "  'everi',\n",
       "  'olymp',\n",
       "  'shoot',\n",
       "  'event'],\n",
       " ['largest',\n",
       "  'ever',\n",
       "  'invest',\n",
       "  'collabor',\n",
       "  'nation',\n",
       "  '1',\n",
       "  'world',\n",
       "  'war',\n",
       "  '2',\n",
       "  'u',\n",
       "  'n',\n",
       "  '3',\n",
       "  'intern',\n",
       "  'space',\n",
       "  'station',\n",
       "  '4',\n",
       "  'olymp'],\n",
       " ['reflect',\n",
       "  'rationalia',\n",
       "  'facebook',\n",
       "  'note',\n",
       "  'neil',\n",
       "  'degrass',\n",
       "  'tyson',\n",
       "  'reflect',\n",
       "  'rationalia',\n",
       "  '10154399608556613'],\n",
       " ['multivers',\n",
       "  'exist',\n",
       "  'one',\n",
       "  'univers',\n",
       "  'foxnew',\n",
       "  'report',\n",
       "  'true',\n",
       "  'anoth',\n",
       "  'msnbc',\n",
       "  'report',\n",
       "  'true'],\n",
       " ['everyth', 'true', 'multivers'],\n",
       " ['look',\n",
       "  'planet',\n",
       "  'friday',\n",
       "  'sky',\n",
       "  'twilight',\n",
       "  'find',\n",
       "  'thin',\n",
       "  'crescent',\n",
       "  'moon',\n",
       "  'left',\n",
       "  'jupit',\n",
       "  'nearbi'],\n",
       " ['low',\n",
       "  'west',\n",
       "  'eve',\n",
       "  'find',\n",
       "  'thin',\n",
       "  'crescent',\n",
       "  'moon',\n",
       "  'look',\n",
       "  'back',\n",
       "  'curtain',\n",
       "  'dusk',\n",
       "  'sun',\n",
       "  'left',\n",
       "  'behind'],\n",
       " ['school',\n",
       "  'often',\n",
       "  'fail',\n",
       "  'simultan',\n",
       "  'train',\n",
       "  'student',\n",
       "  'skeptic',\n",
       "  'claim',\n",
       "  'embrac',\n",
       "  'weight',\n",
       "  'evid'],\n",
       " ['sometim',\n",
       "  'find',\n",
       "  'red',\n",
       "  'blue',\n",
       "  'simpli',\n",
       "  'opposit',\n",
       "  'side',\n",
       "  'spectrum',\n",
       "  'one',\n",
       "  'anoth'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'cosmic',\n",
       "  'queri',\n",
       "  'scienc',\n",
       "  'human',\n",
       "  'war',\n",
       "  'w',\n",
       "  'mary_roach',\n",
       "  'itun',\n",
       "  '29uuljt'],\n",
       " ['met',\n",
       "  'gameofthron',\n",
       "  'star',\n",
       "  'isaac_h_wright',\n",
       "  'comic_con',\n",
       "  'card',\n",
       "  'carri',\n",
       "  'geek',\n",
       "  'recit',\n",
       "  'pi',\n",
       "  '40',\n",
       "  'decim',\n",
       "  'ywntnpae00'],\n",
       " ['etern',\n",
       "  'geek',\n",
       "  'wisdom',\n",
       "  'life',\n",
       "  'univers',\n",
       "  'may',\n",
       "  'signal',\n",
       "  'high',\n",
       "  'nois',\n",
       "  'low'],\n",
       " ['seem',\n",
       "  'everi',\n",
       "  'decad',\n",
       "  'world',\n",
       "  'goe',\n",
       "  'batshit',\n",
       "  'crazi',\n",
       "  'long',\n",
       "  'enough',\n",
       "  'forget',\n",
       "  'last',\n",
       "  'time',\n",
       "  'world',\n",
       "  'went',\n",
       "  'batshit',\n",
       "  'crazi'],\n",
       " ['appar', 'red', 'blue', 'fight', 'one', 'anoth', 'decad', 'dncpowwpyu'],\n",
       " ['dark',\n",
       "  'matter',\n",
       "  'short',\n",
       "  'essay',\n",
       "  'physicist',\n",
       "  'polic',\n",
       "  '1500',\n",
       "  'word',\n",
       "  'facebook',\n",
       "  'note',\n",
       "  'neil',\n",
       "  'degrass',\n",
       "  'tyson',\n",
       "  'dark',\n",
       "  'matter',\n",
       "  '10154327926476613'],\n",
       " ['enjoy',\n",
       "  'color',\n",
       "  'firework',\n",
       "  'tonight',\n",
       "  'thank',\n",
       "  'aluminum',\n",
       "  'barium',\n",
       "  'calcium',\n",
       "  'chlorin',\n",
       "  'copper',\n",
       "  'iron',\n",
       "  'nitrogen',\n",
       "  'oxygen',\n",
       "  'sodium',\n",
       "  'strontium'],\n",
       " ['citizen', 'rationalia', 'wot8pw2baj'],\n",
       " ['earth',\n",
       "  'need',\n",
       "  'virtual',\n",
       "  'countri',\n",
       "  'rationalia',\n",
       "  'one',\n",
       "  'line',\n",
       "  'constitut',\n",
       "  'polici',\n",
       "  'shall',\n",
       "  'base',\n",
       "  'weight',\n",
       "  'evid'],\n",
       " ['comment',\n",
       "  'thread',\n",
       "  'viru',\n",
       "  'urg',\n",
       "  'argu',\n",
       "  'vocifer',\n",
       "  'even',\n",
       "  'actual',\n",
       "  'idea',\n",
       "  'talk'],\n",
       " ['best',\n",
       "  'friend',\n",
       "  'actual',\n",
       "  'everi',\n",
       "  'one',\n",
       "  'best',\n",
       "  'friend',\n",
       "  'made',\n",
       "  'chemic'],\n",
       " ['june',\n",
       "  '20',\n",
       "  'vs',\n",
       "  'june',\n",
       "  '21',\n",
       "  'solstic',\n",
       "  'equinox',\n",
       "  'annual',\n",
       "  'migrat',\n",
       "  '6',\n",
       "  'hr',\n",
       "  'later',\n",
       "  'leap',\n",
       "  'year',\n",
       "  'reset',\n",
       "  '24',\n",
       "  'hr',\n",
       "  'earlier'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'climat',\n",
       "  'chang',\n",
       "  'futur',\n",
       "  'algor',\n",
       "  'itunespodcast',\n",
       "  '1uegrsz'],\n",
       " ['sometim', 'find', 'color', 'rainbow', 'flag', 'fl9ajujank'],\n",
       " ['peopl',\n",
       "  'take',\n",
       "  'leav',\n",
       "  'indigo',\n",
       "  'rainbow',\n",
       "  'color',\n",
       "  'newton',\n",
       "  'mystic',\n",
       "  'fascin',\n",
       "  '7',\n",
       "  'stuck'],\n",
       " ['newton',\n",
       "  'assign',\n",
       "  'seven',\n",
       "  'color',\n",
       "  'color',\n",
       "  'continu',\n",
       "  'rainbow',\n",
       "  'red',\n",
       "  'orang',\n",
       "  'yellow',\n",
       "  'green',\n",
       "  'blue',\n",
       "  'indigo',\n",
       "  'violet',\n",
       "  'meet',\n",
       "  'roy',\n",
       "  'g',\n",
       "  'biv'],\n",
       " ['vision',\n",
       "  'like',\n",
       "  'startrek',\n",
       "  'giordi',\n",
       "  'rainbow',\n",
       "  'would',\n",
       "  'look',\n",
       "  'twice',\n",
       "  'thick',\n",
       "  'includ',\n",
       "  'part',\n",
       "  'ultraviolet',\n",
       "  'infrar'],\n",
       " ['isaac',\n",
       "  'newton',\n",
       "  'optick',\n",
       "  '1704',\n",
       "  'publish',\n",
       "  'discoveri',\n",
       "  'white',\n",
       "  'light',\n",
       "  'compos',\n",
       "  'color',\n",
       "  'color',\n",
       "  'rainbow'],\n",
       " ['rainbow',\n",
       "  'form',\n",
       "  'broadsid',\n",
       "  'line',\n",
       "  'sight',\n",
       "  'pot',\n",
       "  'gold',\n",
       "  'base',\n",
       "  'remain',\n",
       "  'etern',\n",
       "  'reach'],\n",
       " ['rainbow',\n",
       "  'alway',\n",
       "  'angular',\n",
       "  'size',\n",
       "  'sky',\n",
       "  'variou',\n",
       "  'segment',\n",
       "  'circl',\n",
       "  '84',\n",
       "  'degre',\n",
       "  'across'],\n",
       " ['exact',\n",
       "  'rainbow',\n",
       "  'us',\n",
       "  'see',\n",
       "  'sky',\n",
       "  'entir',\n",
       "  'person',\n",
       "  'yet',\n",
       "  'commun',\n",
       "  'gift',\n",
       "  'law',\n",
       "  'optic'],\n",
       " ['odd',\n",
       "  'mani',\n",
       "  'american',\n",
       "  'invok',\n",
       "  '2nd',\n",
       "  'amend',\n",
       "  'justifi',\n",
       "  'gun',\n",
       "  'ownership',\n",
       "  'rather',\n",
       "  'explor',\n",
       "  'whether',\n",
       "  'good',\n",
       "  'idea'],\n",
       " ['common',\n",
       "  'evid',\n",
       "  'bia',\n",
       "  'candid',\n",
       "  'best',\n",
       "  'find',\n",
       "  'absolut',\n",
       "  'noth',\n",
       "  'good',\n",
       "  'say',\n",
       "  'candid'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'startalk',\n",
       "  'live',\n",
       "  'beacon',\n",
       "  'pt',\n",
       "  '1',\n",
       "  'chase',\n",
       "  'comet',\n",
       "  'itunespodcast',\n",
       "  'appl',\n",
       "  'co',\n",
       "  '1ob5vyt'],\n",
       " ['inde',\n",
       "  'atop',\n",
       "  'burj',\n",
       "  'khalifa',\n",
       "  'dubai',\n",
       "  'get',\n",
       "  'four',\n",
       "  'extra',\n",
       "  'minut',\n",
       "  'daylight',\n",
       "  'two',\n",
       "  'morn',\n",
       "  'two',\n",
       "  'even'],\n",
       " ['top',\n",
       "  'burj',\n",
       "  'khalifa',\n",
       "  'dubai',\n",
       "  'daytim',\n",
       "  'ramadan',\n",
       "  'fast',\n",
       "  'last',\n",
       "  '2',\n",
       "  'min',\n",
       "  'longer',\n",
       "  'due',\n",
       "  'later',\n",
       "  'sunset',\n",
       "  'vwcoekm6al'],\n",
       " ['elect', 'ever', 'two', 'kind', 'voter', 'inform'],\n",
       " ['may',\n",
       "  'greatest',\n",
       "  '20th',\n",
       "  'centuri',\n",
       "  'american',\n",
       "  'stori',\n",
       "  'muhammad',\n",
       "  'ali',\n",
       "  'rest',\n",
       "  'peac',\n",
       "  '1942',\n",
       "  '2016'],\n",
       " ['sometim',\n",
       "  'wonder',\n",
       "  'common',\n",
       "  'sens',\n",
       "  'actual',\n",
       "  'uncommon',\n",
       "  'land',\n",
       "  'mayb',\n",
       "  'rare',\n",
       "  'commod',\n",
       "  'cultiv',\n",
       "  'cherish'],\n",
       " ['mani', 'problem', 'appear', 'hard', 'yet', 'smart', 'enough', 'solv'],\n",
       " ['odd',\n",
       "  'mani',\n",
       "  'want',\n",
       "  'less',\n",
       "  'govern',\n",
       "  'live',\n",
       "  'nonetheless',\n",
       "  'want',\n",
       "  'govern',\n",
       "  'dictat',\n",
       "  'sleep',\n",
       "  'marri'],\n",
       " ['met',\n",
       "  'nbcsnl',\n",
       "  'jaypharoah',\n",
       "  'flight',\n",
       "  'remind',\n",
       "  'comedi',\n",
       "  'give',\n",
       "  'lift',\n",
       "  'aerodynam',\n",
       "  'itselfp',\n",
       "  'ftpzlw71cv'],\n",
       " ['geeki',\n",
       "  'bar',\n",
       "  'name',\n",
       "  'weather',\n",
       "  'weeni',\n",
       "  'iso',\n",
       "  'bar',\n",
       "  'dapper',\n",
       "  'eleph',\n",
       "  'ba',\n",
       "  'bar',\n",
       "  '21',\n",
       "  'li',\n",
       "  'st',\n",
       "  'l',\n",
       "  'bc7202fd',\n",
       "  '9556',\n",
       "  '4daf',\n",
       "  'aa31',\n",
       "  'e9794adec256'],\n",
       " ['astrophysicist', 'suppos', 'day', 'job', 'actual', 'night', 'job'],\n",
       " ['skeptic',\n",
       "  'question',\n",
       "  'claim',\n",
       "  'embrac',\n",
       "  'evid',\n",
       "  'denier',\n",
       "  'question',\n",
       "  'claim',\n",
       "  'reject',\n",
       "  'evid'],\n",
       " ['note',\n",
       "  'space',\n",
       "  'alien',\n",
       "  'greeter',\n",
       "  'arriv',\n",
       "  'fli',\n",
       "  'saucer',\n",
       "  'need',\n",
       "  'runway',\n",
       "  'light',\n",
       "  'xer3hahkec'],\n",
       " ['cool',\n",
       "  'video',\n",
       "  'consist',\n",
       "  'known',\n",
       "  'law',\n",
       "  'physic',\n",
       "  'travel',\n",
       "  'via',\n",
       "  'wormhol',\n",
       "  'would',\n",
       "  'obviat',\n",
       "  'blodeja',\n",
       "  '731077222585401344'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'cosmic',\n",
       "  'queri',\n",
       "  'stellar',\n",
       "  'smorgasbord',\n",
       "  'w',\n",
       "  'chuckliu',\n",
       "  'itunespodcast',\n",
       "  '1q4lrah'],\n",
       " ['half',\n",
       "  'volum',\n",
       "  'ice',\n",
       "  'nobodi',\n",
       "  'surpris',\n",
       "  'share',\n",
       "  'properti',\n",
       "  'comet',\n",
       "  'jennawaremsw',\n",
       "  '730715489614368768'],\n",
       " ['nobodi', 'love', 'exoplanet', 'badastronom', '730420136696369156'],\n",
       " ['tell',\n",
       "  'truth',\n",
       "  'begin',\n",
       "  'sentenc',\n",
       "  'tell',\n",
       "  'truth',\n",
       "  'throw',\n",
       "  'question',\n",
       "  'els',\n",
       "  'previou',\n",
       "  'said'],\n",
       " ['candid',\n",
       "  'endors',\n",
       "  'matter',\n",
       "  'rather',\n",
       "  'famou',\n",
       "  'person',\n",
       "  'organ',\n",
       "  'media',\n",
       "  'entiti',\n",
       "  'think'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'promis',\n",
       "  'peril',\n",
       "  'genom',\n",
       "  'revolut',\n",
       "  'itunespodcast',\n",
       "  '1sznc5v'],\n",
       " ['full',\n",
       "  'list',\n",
       "  'cosmic',\n",
       "  'car',\n",
       "  'name',\n",
       "  'ford',\n",
       "  'well',\n",
       "  'gm',\n",
       "  'especi',\n",
       "  'chevrolet',\n",
       "  'line',\n",
       "  '1rfeiim'],\n",
       " ['even',\n",
       "  'cosmic',\n",
       "  'car',\n",
       "  'name',\n",
       "  'aerostar',\n",
       "  'apollo',\n",
       "  'ari',\n",
       "  'aurora',\n",
       "  'comet',\n",
       "  'focu',\n",
       "  'fusion',\n",
       "  'gemini',\n",
       "  'meteor',\n",
       "  'pulsar',\n",
       "  'solera',\n",
       "  'scorpio',\n",
       "  'telstar',\n",
       "  'vega'],\n",
       " ['cosmic',\n",
       "  'car',\n",
       "  'name',\n",
       "  'astro',\n",
       "  'geo',\n",
       "  'mercuri',\n",
       "  'eclips',\n",
       "  'equinox',\n",
       "  'galaxi',\n",
       "  'infin',\n",
       "  'prizm',\n",
       "  'solari',\n",
       "  'saturn',\n",
       "  'subaru',\n",
       "  'solstic',\n",
       "  'spectra',\n",
       "  'tauru'],\n",
       " ['gotta',\n",
       "  'love',\n",
       "  'classic',\n",
       "  'chevi',\n",
       "  'nova',\n",
       "  'sure',\n",
       "  'gener',\n",
       "  'motor',\n",
       "  'knew',\n",
       "  'car',\n",
       "  'share',\n",
       "  'name',\n",
       "  'star',\n",
       "  'explod'],\n",
       " ['subaru',\n",
       "  'japanes',\n",
       "  'call',\n",
       "  'pleiad',\n",
       "  'cluster',\n",
       "  'car',\n",
       "  'logo',\n",
       "  'evok',\n",
       "  'six',\n",
       "  'brightest',\n",
       "  'star',\n",
       "  'bisozxqw2o'],\n",
       " ['alway', 'want', 'call', 'peopl', 'like', 'astronomi', 'galacto', 'intoler'],\n",
       " ['staff',\n",
       "  'favorit',\n",
       "  'startalkradio',\n",
       "  'w',\n",
       "  'sethmacfarlan',\n",
       "  '1ssgbb3',\n",
       "  'vega',\n",
       "  'crooner',\n",
       "  '1tuok3o'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'race',\n",
       "  'extinct',\n",
       "  'w',\n",
       "  'leilanimunt',\n",
       "  'eugenemirman',\n",
       "  'itunespodcast',\n",
       "  '1vi4fpc'],\n",
       " ['odd',\n",
       "  'earthday',\n",
       "  'exist',\n",
       "  'day',\n",
       "  'instead',\n",
       "  'mayb',\n",
       "  'extend',\n",
       "  'whole',\n",
       "  'year',\n",
       "  'repeat',\n",
       "  'annual'],\n",
       " ['earth',\n",
       "  'accord',\n",
       "  'rock',\n",
       "  'earth',\n",
       "  'day',\n",
       "  'must',\n",
       "  'see',\n",
       "  'video',\n",
       "  '8min',\n",
       "  '30sec',\n",
       "  'watch',\n",
       "  'end',\n",
       "  'youtub',\n",
       "  'watch',\n",
       "  'v',\n",
       "  'hopwxnfu7'],\n",
       " ['mani',\n",
       "  'refer',\n",
       "  'planet',\n",
       "  'mother',\n",
       "  'earth',\n",
       "  'ignor',\n",
       "  'much',\n",
       "  'kill',\n",
       "  'forc',\n",
       "  'hurrican',\n",
       "  'earthquak',\n",
       "  'tsunami'],\n",
       " ['save',\n",
       "  'earth',\n",
       "  'realli',\n",
       "  'mean',\n",
       "  'save',\n",
       "  'human',\n",
       "  'save',\n",
       "  'life',\n",
       "  'earth',\n",
       "  'earth',\n",
       "  'planet',\n",
       "  'outlast',\n",
       "  'extinct'],\n",
       " ['short',\n",
       "  'mountain',\n",
       "  'seem',\n",
       "  'tall',\n",
       "  'mortal',\n",
       "  'earth',\n",
       "  'seem',\n",
       "  'etern',\n",
       "  'spacecraft',\n",
       "  'slow',\n",
       "  'univers',\n",
       "  'seem',\n",
       "  'vast'],\n",
       " ['elev',\n",
       "  'differ',\n",
       "  'mariana',\n",
       "  'trench',\n",
       "  'mount',\n",
       "  'everest',\n",
       "  'summit',\n",
       "  'mere',\n",
       "  '12',\n",
       "  'mile',\n",
       "  'manhattan',\n",
       "  'mile',\n",
       "  'longer'],\n",
       " ['smooth',\n",
       "  'earth',\n",
       "  'shrunk',\n",
       "  'inch',\n",
       "  'across',\n",
       "  'earth',\n",
       "  'would',\n",
       "  'feel',\n",
       "  'smooth',\n",
       "  'billiard',\n",
       "  'hall',\n",
       "  'cue',\n",
       "  'ball'],\n",
       " ['earth',\n",
       "  'get',\n",
       "  'slam',\n",
       "  'hundr',\n",
       "  'ton',\n",
       "  'meteor',\n",
       "  'per',\n",
       "  'day',\n",
       "  'harmlessli',\n",
       "  'vapor',\n",
       "  'atmospher',\n",
       "  'shoot',\n",
       "  'star'],\n",
       " ['thin',\n",
       "  'air',\n",
       "  'size',\n",
       "  'earth',\n",
       "  'atmospher',\n",
       "  'rel',\n",
       "  'earth',\n",
       "  'skin',\n",
       "  'appl',\n",
       "  'rel',\n",
       "  'appl'],\n",
       " ['april',\n",
       "  '22',\n",
       "  '2016',\n",
       "  'earth',\n",
       "  'day',\n",
       "  'grace',\n",
       "  'full',\n",
       "  'moon',\n",
       "  'occur',\n",
       "  'averag',\n",
       "  'everi',\n",
       "  'thirti',\n",
       "  'year'],\n",
       " ['earth',\n",
       "  'feel',\n",
       "  'big',\n",
       "  'littl',\n",
       "  'pour',\n",
       "  'million',\n",
       "  'earth',\n",
       "  'hallow',\n",
       "  'sun',\n",
       "  'still',\n",
       "  'room'],\n",
       " ['earth',\n",
       "  'day',\n",
       "  'found',\n",
       "  '1970',\n",
       "  'apollo',\n",
       "  'moon',\n",
       "  'mission',\n",
       "  'look',\n",
       "  'back',\n",
       "  'discov',\n",
       "  'earth',\n",
       "  'first',\n",
       "  'time'],\n",
       " ['feelin', 'earthi', 'today'],\n",
       " ['know',\n",
       "  'sound',\n",
       "  'like',\n",
       "  'dove',\n",
       "  'cri',\n",
       "  'absenc',\n",
       "  'music',\n",
       "  'loss',\n",
       "  'artist',\n",
       "  'rip',\n",
       "  'princ',\n",
       "  '1958',\n",
       "  '2016'],\n",
       " ['comput',\n",
       "  'voic',\n",
       "  'countdown',\n",
       "  'destruct',\n",
       "  'curious',\n",
       "  'calm',\n",
       "  'want',\n",
       "  'panic',\n",
       "  'end',\n",
       "  'world'],\n",
       " ['post',\n",
       "  'billny',\n",
       "  'put',\n",
       "  'climat',\n",
       "  'money',\n",
       "  'mouth',\n",
       "  'video',\n",
       "  '2m',\n",
       "  '45',\n",
       "  'youtub',\n",
       "  'watch',\n",
       "  'v',\n",
       "  'c4bdk',\n",
       "  'ppgb'],\n",
       " ['nephew',\n",
       "  'idaho',\n",
       "  'puzzl',\n",
       "  'lock',\n",
       "  'nyc',\n",
       "  'apt',\n",
       "  'door',\n",
       "  'ask',\n",
       "  'lock',\n",
       "  'home',\n",
       "  'repli',\n",
       "  'shotgun'],\n",
       " ['justpost',\n",
       "  'startalkradio',\n",
       "  'cosmic',\n",
       "  'queri',\n",
       "  'scienc',\n",
       "  'moral',\n",
       "  'w',\n",
       "  'michaelsherm',\n",
       "  'itunespodcast',\n",
       "  '1mytxcq'],\n",
       " ['greenland',\n",
       "  'antarct',\n",
       "  'ice',\n",
       "  'sheet',\n",
       "  'melt',\n",
       "  'sea',\n",
       "  'level',\n",
       "  'rise',\n",
       "  'statu',\n",
       "  'liberti',\n",
       "  'ipad',\n",
       "  'knqkfwrpz2'],\n",
       " ['ever',\n",
       "  'met',\n",
       "  'space',\n",
       "  'alien',\n",
       "  'resist',\n",
       "  'shake',\n",
       "  'extend',\n",
       "  'appendag',\n",
       "  'know',\n",
       "  'sure',\n",
       "  'detail',\n",
       "  'alien',\n",
       "  'anatomi'],\n",
       " ['justpost',\n",
       "  'startalkradio',\n",
       "  'unravel',\n",
       "  'reddit',\n",
       "  'w',\n",
       "  'alexisohanian',\n",
       "  'also',\n",
       "  'jeffjarvi',\n",
       "  'itunespodcast',\n",
       "  '1tgrksl'],\n",
       " ['train', 'mind', 'think', 'inocul', 'desper', 'want', 'tell', 'think'],\n",
       " ['red', 'vs', 'blue', 'polit', 'america', 'sometim', 'find', 'purpl', 'haze'],\n",
       " ['get',\n",
       "  'ass',\n",
       "  'mar',\n",
       "  'yup',\n",
       "  'earlier',\n",
       "  'today',\n",
       "  'got',\n",
       "  'touch',\n",
       "  'therealbuzz',\n",
       "  'aldrin',\n",
       "  'ass',\n",
       "  'ndwmuzmrn9'],\n",
       " ['child',\n",
       "  'know',\n",
       "  'time',\n",
       "  'new',\n",
       "  'number',\n",
       "  'eleventi',\n",
       "  'also',\n",
       "  'overdu',\n",
       "  'new',\n",
       "  'dinosaur',\n",
       "  'call',\n",
       "  'thesauru'],\n",
       " ['toddler',\n",
       "  'know',\n",
       "  'overdu',\n",
       "  'new',\n",
       "  'word',\n",
       "  'elemeno',\n",
       "  'letter',\n",
       "  'k',\n",
       "  'p',\n",
       "  'alphabet'],\n",
       " ['never',\n",
       "  'seen',\n",
       "  'bar',\n",
       "  'fight',\n",
       "  'break',\n",
       "  'peopl',\n",
       "  'drink',\n",
       "  'wine',\n",
       "  'beer',\n",
       "  'ye',\n",
       "  'hard',\n",
       "  'liquor',\n",
       "  'ye',\n",
       "  'wine'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'cosmic',\n",
       "  'queri',\n",
       "  'new',\n",
       "  'mysteri',\n",
       "  'univers',\n",
       "  'itunespodcast',\n",
       "  '1pclv1r'],\n",
       " ['benaffleck',\n",
       "  '2',\n",
       "  'differ',\n",
       "  'superhero',\n",
       "  '2',\n",
       "  'differ',\n",
       "  'film',\n",
       "  '2',\n",
       "  'differ',\n",
       "  'comic',\n",
       "  'univers',\n",
       "  'marvel',\n",
       "  'daredevil',\n",
       "  'dc',\n",
       "  'batman'],\n",
       " ['batman',\n",
       "  'want',\n",
       "  'badli',\n",
       "  'bat',\n",
       "  'might',\n",
       "  'intrigu',\n",
       "  'like',\n",
       "  'marvel',\n",
       "  'daredevil',\n",
       "  'also',\n",
       "  'blind',\n",
       "  'like',\n",
       "  'bat'],\n",
       " ['batmanvsuperman',\n",
       "  'question',\n",
       "  'remain',\n",
       "  'would',\n",
       "  'realdonaldtrump',\n",
       "  'deport',\n",
       "  'superman',\n",
       "  'illeg',\n",
       "  'alien',\n",
       "  'usa'],\n",
       " ['batmanvsuperman',\n",
       "  'gotta',\n",
       "  'side',\n",
       "  'superman',\n",
       "  'space',\n",
       "  'alien',\n",
       "  'exoplanet',\n",
       "  'astrophys',\n",
       "  'roll'],\n",
       " ['geeki',\n",
       "  'sky',\n",
       "  'coordin',\n",
       "  'krypton',\n",
       "  'constel',\n",
       "  'corvu',\n",
       "  'lh',\n",
       "  '2520',\n",
       "  'ra',\n",
       "  '2000',\n",
       "  '12h',\n",
       "  '10m',\n",
       "  '05',\n",
       "  '60',\n",
       "  'dec',\n",
       "  '2000',\n",
       "  '15d',\n",
       "  '04',\n",
       "  '15',\n",
       "  '66'],\n",
       " ['brandonfinlen',\n",
       "  'nice',\n",
       "  'vest',\n",
       "  'realli',\n",
       "  'one',\n",
       "  'like',\n",
       "  'brandon',\n",
       "  'look',\n",
       "  'photo'],\n",
       " ['met',\n",
       "  'superman',\n",
       "  'year',\n",
       "  'ago',\n",
       "  'hayden',\n",
       "  'planetarium',\n",
       "  'help',\n",
       "  'find',\n",
       "  'krypton',\n",
       "  'nice',\n",
       "  'man',\n",
       "  'oys7oy91zj'],\n",
       " ['might',\n",
       "  'superman',\n",
       "  'super',\n",
       "  'digest',\n",
       "  'system',\n",
       "  'startalkradio',\n",
       "  'video',\n",
       "  'clip',\n",
       "  '4m',\n",
       "  'youtub',\n",
       "  'watch',\n",
       "  'v',\n",
       "  'hbfcwyizhg'],\n",
       " ['anybodi',\n",
       "  'ask',\n",
       "  'gregorian',\n",
       "  'calendar',\n",
       "  'rule',\n",
       "  'unintent',\n",
       "  'prevent',\n",
       "  'eclips',\n",
       "  'ever',\n",
       "  'occur',\n",
       "  'easter',\n",
       "  'sunday'],\n",
       " ['fyi',\n",
       "  'tonight',\n",
       "  'first',\n",
       "  'full',\n",
       "  'moon',\n",
       "  'march',\n",
       "  'equinox',\n",
       "  'gregorian',\n",
       "  'calendar',\n",
       "  'rule',\n",
       "  'sunday',\n",
       "  'follow',\n",
       "  'easter'],\n",
       " ['justpost',\n",
       "  'startalkradio',\n",
       "  'protect',\n",
       "  'earth',\n",
       "  'asteroid',\n",
       "  'w',\n",
       "  'rusti',\n",
       "  'schweickart',\n",
       "  'itunespodcast',\n",
       "  '1ub9qxm'],\n",
       " ['happi',\n",
       "  '10th',\n",
       "  'birthday',\n",
       "  'note',\n",
       "  'howev',\n",
       "  'trend',\n",
       "  'lovetwitt',\n",
       "  'hashtag',\n",
       "  'grossli',\n",
       "  'overst',\n",
       "  'emot'],\n",
       " ['alway',\n",
       "  'wonder',\n",
       "  'dr',\n",
       "  'dolittl',\n",
       "  'push',\n",
       "  'pull',\n",
       "  'llama',\n",
       "  'suppos',\n",
       "  'poop',\n",
       "  'r1y0cc9es3'],\n",
       " ['also',\n",
       "  'sunris',\n",
       "  'sunset',\n",
       "  'tabl',\n",
       "  'refer',\n",
       "  'spot',\n",
       "  'sun',\n",
       "  'record',\n",
       "  'extra',\n",
       "  'sun',\n",
       "  'width',\n",
       "  'light',\n",
       "  'everi',\n",
       "  'day'],\n",
       " ['equinox',\n",
       "  'equal',\n",
       "  'night',\n",
       "  'latin',\n",
       "  'refract',\n",
       "  'earth',\n",
       "  'atmospher',\n",
       "  'add',\n",
       "  'minut',\n",
       "  'extra',\n",
       "  'sunshin',\n",
       "  'sunris',\n",
       "  'sunset'],\n",
       " ['happi',\n",
       "  'march',\n",
       "  'equinox',\n",
       "  'resid',\n",
       "  'planet',\n",
       "  'earth',\n",
       "  'first',\n",
       "  'day',\n",
       "  'spring',\n",
       "  'north',\n",
       "  'equat',\n",
       "  'first',\n",
       "  'day',\n",
       "  'autumn',\n",
       "  'south'],\n",
       " ['real',\n",
       "  'wrestl',\n",
       "  'come',\n",
       "  'msg',\n",
       "  'first',\n",
       "  'time',\n",
       "  'remind',\n",
       "  'sport',\n",
       "  'appear',\n",
       "  'grecian',\n",
       "  'urn',\n",
       "  'uhvreokrfv'],\n",
       " ['happi', 'saint', 'patrick', 'day', 'presid', 'barack', 'bama'],\n",
       " ['mother',\n",
       "  'natur',\n",
       "  'genet',\n",
       "  'modifi',\n",
       "  'organ',\n",
       "  'nearli',\n",
       "  'four',\n",
       "  'billion',\n",
       "  'year',\n",
       "  'farmer',\n",
       "  'ten',\n",
       "  'thousand',\n",
       "  'year'],\n",
       " ['happi',\n",
       "  'pi',\n",
       "  'day',\n",
       "  'post',\n",
       "  'best',\n",
       "  'pi',\n",
       "  'tweet',\n",
       "  'year',\n",
       "  'ago',\n",
       "  'today',\n",
       "  'wish',\n",
       "  'happi',\n",
       "  '137th',\n",
       "  'birthday',\n",
       "  'albert',\n",
       "  'einstein'],\n",
       " ['wonder',\n",
       "  'live',\n",
       "  'like',\n",
       "  'flintston',\n",
       "  'modern',\n",
       "  'stoneag',\n",
       "  'famili',\n",
       "  'metal',\n",
       "  'never',\n",
       "  'discov',\n",
       "  'earth'],\n",
       " ['peopl',\n",
       "  'anti',\n",
       "  'trump',\n",
       "  'actual',\n",
       "  'anti',\n",
       "  'trump',\n",
       "  'support',\n",
       "  'oppos',\n",
       "  'free',\n",
       "  'citizen',\n",
       "  'vote',\n",
       "  'realdonaldtrump'],\n",
       " ['gene', 'celibaci', 'inherit'],\n",
       " ['think', 'tri', 'one', 'biologist'],\n",
       " ['pzmyer',\n",
       "  '1te9mz',\n",
       "  'point',\n",
       "  'ejwillingham',\n",
       "  'review',\n",
       "  'onforb',\n",
       "  'es',\n",
       "  '1sjjn3j',\n",
       "  'speci',\n",
       "  'sex',\n",
       "  'hurt'],\n",
       " ['ever', 'speci', 'sex', 'hurt', 'sure', 'went', 'extinct', 'long', 'ago'],\n",
       " ['occasion',\n",
       "  'wonder',\n",
       "  'whether',\n",
       "  'entir',\n",
       "  'univers',\n",
       "  'noth',\n",
       "  'snow',\n",
       "  'globe',\n",
       "  'live',\n",
       "  'room',\n",
       "  'mantl',\n",
       "  'alien'],\n",
       " ['hayden',\n",
       "  'joe',\n",
       "  'rao',\n",
       "  'alert',\n",
       "  'alaskaair',\n",
       "  'tuesday',\n",
       "  'solar',\n",
       "  'eclips',\n",
       "  'get',\n",
       "  'flight',\n",
       "  '870',\n",
       "  'fli',\n",
       "  'directli',\n",
       "  'moon',\n",
       "  'shadow'],\n",
       " ['flight',\n",
       "  'entertain',\n",
       "  'alaskaair',\n",
       "  'flight',\n",
       "  '870',\n",
       "  'anc',\n",
       "  'hnl',\n",
       "  'tue',\n",
       "  'march',\n",
       "  '8',\n",
       "  'modifi',\n",
       "  'flight',\n",
       "  'path',\n",
       "  'youtub',\n",
       "  'watch',\n",
       "  'v',\n",
       "  'yboa81xevna'],\n",
       " ['also',\n",
       "  'recreat',\n",
       "  'consum',\n",
       "  'larg',\n",
       "  'quantiti',\n",
       "  'dihydrogen',\n",
       "  'monoxid',\n",
       "  'street',\n",
       "  'pay',\n",
       "  '2',\n",
       "  '000',\n",
       "  'per',\n",
       "  'megagram'],\n",
       " ['everi',\n",
       "  'tweet',\n",
       "  'take',\n",
       "  'deep',\n",
       "  'hit',\n",
       "  'gaseou',\n",
       "  'cocktail',\n",
       "  'compris',\n",
       "  '78',\n",
       "  'n2',\n",
       "  '21',\n",
       "  'o2',\n",
       "  'long',\n",
       "  'rever',\n",
       "  'elixir',\n",
       "  'life'],\n",
       " ['simultan',\n",
       "  'flatter',\n",
       "  'disturb',\n",
       "  'post',\n",
       "  'variou',\n",
       "  'tweet',\n",
       "  'peopl',\n",
       "  'tweet',\n",
       "  'back',\n",
       "  'wonder',\n",
       "  'drug'],\n",
       " ['closest',\n",
       "  'thing',\n",
       "  'fatal',\n",
       "  'pass',\n",
       "  'portal',\n",
       "  'anoth',\n",
       "  'dimens',\n",
       "  'fish',\n",
       "  'get',\n",
       "  'yank',\n",
       "  'water',\n",
       "  'eaten'],\n",
       " ['hear',\n",
       "  'flat',\n",
       "  'earth',\n",
       "  'movement',\n",
       "  'may',\n",
       "  'gain',\n",
       "  'momentum',\n",
       "  'around',\n",
       "  'globe'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'season',\n",
       "  'premier',\n",
       "  'gaze',\n",
       "  'futur',\n",
       "  'w',\n",
       "  'ray',\n",
       "  'kurzweil',\n",
       "  'itunespodcast',\n",
       "  '1qyxym7'],\n",
       " ['mayb',\n",
       "  'wolv',\n",
       "  'also',\n",
       "  'love',\n",
       "  'ride',\n",
       "  'car',\n",
       "  'hang',\n",
       "  'head',\n",
       "  'window',\n",
       "  'sens',\n",
       "  'rather',\n",
       "  'eat',\n",
       "  'driver'],\n",
       " ['thought',\n",
       "  'alter',\n",
       "  'wolf',\n",
       "  'gene',\n",
       "  'creat',\n",
       "  'dog',\n",
       "  'would',\n",
       "  'imbu',\n",
       "  'delight',\n",
       "  'ride',\n",
       "  'car',\n",
       "  'head',\n",
       "  'window'],\n",
       " ['welcom',\n",
       "  'back',\n",
       "  'earth',\n",
       "  'scott',\n",
       "  'kelli',\n",
       "  'year',\n",
       "  'orbit',\n",
       "  'rel',\n",
       "  'say',\n",
       "  '1',\n",
       "  '100',\n",
       "  'sec',\n",
       "  'younger',\n",
       "  'otherwis'],\n",
       " ['5',\n",
       "  '000',\n",
       "  '000th',\n",
       "  'follow',\n",
       "  'reaffirm',\n",
       "  'honor',\n",
       "  'privileg',\n",
       "  'rub',\n",
       "  'geek',\n",
       "  'underbelli',\n",
       "  'twittervers'],\n",
       " ['would',\n",
       "  'jesu',\n",
       "  'vote',\n",
       "  'wall',\n",
       "  'wealth',\n",
       "  'tortur',\n",
       "  'non',\n",
       "  'starter',\n",
       "  'probabl',\n",
       "  'jewish',\n",
       "  'new',\n",
       "  'yorker',\n",
       "  'vermont'],\n",
       " ['still',\n",
       "  'calendr',\n",
       "  'curiou',\n",
       "  'ever',\n",
       "  'care',\n",
       "  'know',\n",
       "  'leap',\n",
       "  'day',\n",
       "  '3min',\n",
       "  '20sec',\n",
       "  '21sw8i0'],\n",
       " ['born',\n",
       "  'leap',\n",
       "  'day',\n",
       "  'share',\n",
       "  'distinct',\n",
       "  '1',\n",
       "  '1',\n",
       "  '400',\n",
       "  'peopl',\n",
       "  'world'],\n",
       " ['like',\n",
       "  'leap',\n",
       "  'day',\n",
       "  'could',\n",
       "  'instead',\n",
       "  'wait',\n",
       "  '28',\n",
       "  'year',\n",
       "  'insert',\n",
       "  'leap',\n",
       "  'week',\n",
       "  '112',\n",
       "  'year',\n",
       "  'insert',\n",
       "  'leap',\n",
       "  'month'],\n",
       " ['accord',\n",
       "  'gregorian',\n",
       "  'rule',\n",
       "  '1',\n",
       "  '4',\n",
       "  'centuri',\n",
       "  'year',\n",
       "  'leap',\n",
       "  'year',\n",
       "  'rariti',\n",
       "  '2000',\n",
       "  'leap',\n",
       "  'day',\n",
       "  'went',\n",
       "  'larg',\n",
       "  'unnot'],\n",
       " ['leap',\n",
       "  'day',\n",
       "  'misnam',\n",
       "  'leap',\n",
       "  'anywher',\n",
       "  'calendar',\n",
       "  'simpli',\n",
       "  'abruptli',\n",
       "  'catch',\n",
       "  'earth',\n",
       "  'orbit'],\n",
       " ['born',\n",
       "  'leap',\n",
       "  'day',\n",
       "  '1',\n",
       "  '4',\n",
       "  'mani',\n",
       "  'birthday',\n",
       "  'rest',\n",
       "  'us',\n",
       "  'sorri',\n",
       "  '1',\n",
       "  '4th',\n",
       "  'old'],\n",
       " ['earth',\n",
       "  'take',\n",
       "  'nearli',\n",
       "  '365',\n",
       "  '1',\n",
       "  '4',\n",
       "  'day',\n",
       "  'orbit',\n",
       "  'sun',\n",
       "  'bank',\n",
       "  'fraction',\n",
       "  'everi',\n",
       "  '4',\n",
       "  'year',\n",
       "  'add',\n",
       "  'whole',\n",
       "  'day',\n",
       "  'back',\n",
       "  'neediest',\n",
       "  'month'],\n",
       " ['welcom', 'twittervers', '105th', 'leap', 'day', 'gregorian', 'calendar'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'fan',\n",
       "  'favorit',\n",
       "  'season',\n",
       "  '6',\n",
       "  'time',\n",
       "  'capsul',\n",
       "  'part',\n",
       "  '2',\n",
       "  'itunespodcast',\n",
       "  '21y08fi'],\n",
       " ['follow',\n",
       "  'seek',\n",
       "  'hodgepodg',\n",
       "  'brain',\n",
       "  'drop',\n",
       "  'intellectu',\n",
       "  'restless',\n",
       "  'astrophysicist',\n",
       "  'forewarn'],\n",
       " ['want',\n",
       "  'reliabl',\n",
       "  'report',\n",
       "  'happen',\n",
       "  'earth',\n",
       "  'sky',\n",
       "  'follow',\n",
       "  'follow',\n",
       "  'earthskysci',\n",
       "  'ff'],\n",
       " ['like',\n",
       "  'know',\n",
       "  'everi',\n",
       "  'space',\n",
       "  'mission',\n",
       "  'time',\n",
       "  'follow',\n",
       "  'follow',\n",
       "  'planetari',\n",
       "  'societi',\n",
       "  'elakdawalla',\n",
       "  'ff'],\n",
       " ['like',\n",
       "  'random',\n",
       "  'space',\n",
       "  'fact',\n",
       "  'everi',\n",
       "  'follow',\n",
       "  'follow',\n",
       "  'planetari',\n",
       "  'societi',\n",
       "  'randomspacefact',\n",
       "  'ff'],\n",
       " ['steve',\n",
       "  'leichman',\n",
       "  'stevedashoh',\n",
       "  'post',\n",
       "  'funni',\n",
       "  'stuff',\n",
       "  'possibl',\n",
       "  'deserv',\n",
       "  'follow',\n",
       "  '487',\n",
       "  'ff'],\n",
       " ['extermin', 'profess', 'put', 'busi', 'realli', 'good', 'job'],\n",
       " ['one',\n",
       "  'quest',\n",
       "  'life',\n",
       "  'sole',\n",
       "  'search',\n",
       "  'answer',\n",
       "  'find',\n",
       "  'pleasur',\n",
       "  'pose',\n",
       "  'question'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'fan',\n",
       "  'favorit',\n",
       "  'season',\n",
       "  '6',\n",
       "  'time',\n",
       "  'capsul',\n",
       "  'part',\n",
       "  '1',\n",
       "  'itunespodcast',\n",
       "  '1kzwczl'],\n",
       " ['let',\n",
       "  'confess',\n",
       "  'best',\n",
       "  '4d',\n",
       "  'portal',\n",
       "  'product',\n",
       "  'transport',\n",
       "  'drive',\n",
       "  'thru',\n",
       "  'window',\n",
       "  'mcdonald'],\n",
       " ['mayb',\n",
       "  'realli',\n",
       "  'want',\n",
       "  'wormhol',\n",
       "  'ship',\n",
       "  'buy',\n",
       "  'someth',\n",
       "  'onlin',\n",
       "  '4d',\n",
       "  'portal',\n",
       "  'open',\n",
       "  'person',\n",
       "  'hand',\n",
       "  'product'],\n",
       " ['disappoint', 'corrug', 'ship', 'box', 'chang', 'centuri'],\n",
       " ['wonder',\n",
       "  'workplac',\n",
       "  'contain',\n",
       "  'mani',\n",
       "  'boss',\n",
       "  'bask',\n",
       "  'compliment',\n",
       "  'given',\n",
       "  'peopl',\n",
       "  'reli',\n",
       "  'paycheck'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'cosmic',\n",
       "  'queri',\n",
       "  'scienc',\n",
       "  'love',\n",
       "  'w',\n",
       "  'drhelenfish',\n",
       "  'itunespodcast',\n",
       "  '241g4xg'],\n",
       " ['wonder',\n",
       "  'cannib',\n",
       "  'aztec',\n",
       "  'would',\n",
       "  'say',\n",
       "  'watch',\n",
       "  'civil',\n",
       "  'peopl',\n",
       "  'eat',\n",
       "  'symbol',\n",
       "  'heart',\n",
       "  'love',\n",
       "  'one',\n",
       "  'valentin',\n",
       "  'day'],\n",
       " ['venu',\n",
       "  'venusian',\n",
       "  'proper',\n",
       "  'term',\n",
       "  'vener',\n",
       "  'unfortun',\n",
       "  'doctor',\n",
       "  'nab',\n",
       "  'astrophysicist'],\n",
       " ['venu',\n",
       "  'roman',\n",
       "  'goddess',\n",
       "  'love',\n",
       "  'sexual',\n",
       "  'medic',\n",
       "  'doctor',\n",
       "  'assign',\n",
       "  'vener',\n",
       "  'venu',\n",
       "  'relat',\n",
       "  'diseas'],\n",
       " ['happi', 'valentin', 'day', 'twittervers'],\n",
       " ['1916',\n",
       "  'einstein',\n",
       "  'predict',\n",
       "  'graviti',\n",
       "  'wave',\n",
       "  '1917',\n",
       "  'lay',\n",
       "  'foundat',\n",
       "  'laser',\n",
       "  '2016',\n",
       "  'graviti',\n",
       "  'wave',\n",
       "  'discov',\n",
       "  'use',\n",
       "  'laser'],\n",
       " ['never',\n",
       "  'make',\n",
       "  'mistak',\n",
       "  'frontier',\n",
       "  'discoveri',\n",
       "  'mistak',\n",
       "  'made',\n",
       "  'time'],\n",
       " ['today',\n",
       "  'first',\n",
       "  'new',\n",
       "  'moon',\n",
       "  'jan',\n",
       "  '21sr',\n",
       "  'happi',\n",
       "  'new',\n",
       "  'year',\n",
       "  'chines',\n",
       "  'peopl',\n",
       "  'choos',\n",
       "  'chines',\n",
       "  'day'],\n",
       " ['oversea',\n",
       "  'watch',\n",
       "  'sb50',\n",
       "  '4th',\n",
       "  'quarter',\n",
       "  'friend',\n",
       "  'colleagu',\n",
       "  'badastronom',\n",
       "  'take',\n",
       "  'home'],\n",
       " ['helmet',\n",
       "  'illustr',\n",
       "  'sb50',\n",
       "  'bronco',\n",
       "  'mane',\n",
       "  'red',\n",
       "  'highlight',\n",
       "  'panther',\n",
       "  'fur',\n",
       "  'blue',\n",
       "  'highlight'],\n",
       " ['neiltyson', 'onep', 'okbyhh5jzu'],\n",
       " ['wonder', 'refere', 'look', 'like', 'zebra'],\n",
       " ['somebodi',\n",
       "  'enter',\n",
       "  'bet',\n",
       "  'grid',\n",
       "  'sb50',\n",
       "  'number',\n",
       "  '8',\n",
       "  '5',\n",
       "  'combin',\n",
       "  'never',\n",
       "  'hit',\n",
       "  'quarter',\n",
       "  '49',\n",
       "  'year'],\n",
       " ['earth',\n",
       "  'rotat',\n",
       "  '10x',\n",
       "  'faster',\n",
       "  'opposit',\n",
       "  'direct',\n",
       "  'corioli',\n",
       "  'forc',\n",
       "  'would',\n",
       "  'help',\n",
       "  'panther',\n",
       "  'make',\n",
       "  'field',\n",
       "  'goal'],\n",
       " ['fyi', 'deplor', 'bounci', 'anagram', 'beyonc', 'coldplay', 'bruno'],\n",
       " ['alreadi',\n",
       "  'tweet',\n",
       "  'beyonc',\n",
       "  'super',\n",
       "  'bowl',\n",
       "  'xlvii',\n",
       "  'noth',\n",
       "  'add',\n",
       "  'analysi',\n",
       "  'energet'],\n",
       " ['astro',\n",
       "  'folk',\n",
       "  'invent',\n",
       "  'time',\n",
       "  'keep',\n",
       "  'sb50',\n",
       "  'coldplay',\n",
       "  'must',\n",
       "  'sing',\n",
       "  'clock'],\n",
       " ['fyi',\n",
       "  'roman',\n",
       "  'numer',\n",
       "  'zero',\n",
       "  'invent',\n",
       "  'empir',\n",
       "  'tradit',\n",
       "  'christian',\n",
       "  'calendar',\n",
       "  'year',\n",
       "  'zero'],\n",
       " ['triumph',\n",
       "  'arab',\n",
       "  'numer',\n",
       "  'forti',\n",
       "  'nine',\n",
       "  'super',\n",
       "  'bowl',\n",
       "  'enumer',\n",
       "  'roman',\n",
       "  'numer',\n",
       "  'hashtag',\n",
       "  'sb50',\n",
       "  'sbl'],\n",
       " ['sb50',\n",
       "  'footbal',\n",
       "  'field',\n",
       "  'cosmic',\n",
       "  'timelin',\n",
       "  'cavemen',\n",
       "  'present',\n",
       "  'day',\n",
       "  'span',\n",
       "  'turf',\n",
       "  'blade',\n",
       "  'thick',\n",
       "  'end',\n",
       "  'zone'],\n",
       " ['everi',\n",
       "  'day',\n",
       "  'someon',\n",
       "  'could',\n",
       "  'made',\n",
       "  'discoveri',\n",
       "  'cultur',\n",
       "  'polit',\n",
       "  'forc',\n",
       "  'imped',\n",
       "  'sad',\n",
       "  'day',\n",
       "  'civil'],\n",
       " ['look', 'son', 'bitch', 'jyeiov7lgv'],\n",
       " ['scienc',\n",
       "  'human',\n",
       "  'behavior',\n",
       "  'enter',\n",
       "  'equat',\n",
       "  'thing',\n",
       "  'go',\n",
       "  'nonlinear',\n",
       "  'physic',\n",
       "  'easi',\n",
       "  'sociolog',\n",
       "  'hard'],\n",
       " ['four',\n",
       "  'decad',\n",
       "  'reason',\n",
       "  'devot',\n",
       "  'gratitud',\n",
       "  'rip',\n",
       "  'mauric',\n",
       "  'white',\n",
       "  'shine',\n",
       "  'star',\n",
       "  '1941',\n",
       "  '2016',\n",
       "  'founder',\n",
       "  'earth',\n",
       "  'wind',\n",
       "  'fire'],\n",
       " ['sad', 'banana', 'qnx4xv51co'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'valu',\n",
       "  'scienc',\n",
       "  'profbriancox',\n",
       "  'itunespodcast',\n",
       "  '1pfw4lg'],\n",
       " ['time',\n",
       "  'watch',\n",
       "  'ridley',\n",
       "  'scott',\n",
       "  '1982',\n",
       "  'film',\n",
       "  'blade',\n",
       "  'runner',\n",
       "  'fyi',\n",
       "  'three',\n",
       "  'replic',\n",
       "  'incept',\n",
       "  'date',\n",
       "  '2016'],\n",
       " ['chillin',\n",
       "  'larrywilmor',\n",
       "  'second',\n",
       "  'mic',\n",
       "  'drop',\n",
       "  '1ph13v3',\n",
       "  'nightlyshowp',\n",
       "  'jbpmzrrzln'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'colon',\n",
       "  'mar',\n",
       "  'baslansdorp',\n",
       "  'astro_mik',\n",
       "  'itunespodcast',\n",
       "  '1kth1p2'],\n",
       " ['januari',\n",
       "  '28',\n",
       "  '2016',\n",
       "  'thirti',\n",
       "  'year',\n",
       "  'ago',\n",
       "  'today',\n",
       "  'ode',\n",
       "  'challeng',\n",
       "  'b3fap8ann7'],\n",
       " ['dear',\n",
       "  'bobatl',\n",
       "  'astrophysicist',\n",
       "  'rap',\n",
       "  'know',\n",
       "  'peopl',\n",
       "  'one',\n",
       "  'back',\n",
       "  'soundcloud',\n",
       "  'drtyson',\n",
       "  'flat',\n",
       "  'fact'],\n",
       " ['cosmo',\n",
       "  'knowabl',\n",
       "  'childhood',\n",
       "  'curios',\n",
       "  'persist',\n",
       "  'adult',\n",
       "  'inocul',\n",
       "  'other',\n",
       "  'tell',\n",
       "  'think'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'convers',\n",
       "  'alan',\n",
       "  'rickman',\n",
       "  'revisit',\n",
       "  'itunespodcast',\n",
       "  '20jleiw'],\n",
       " ['fyi',\n",
       "  'huffpo',\n",
       "  'phobic',\n",
       "  'post',\n",
       "  'scienc',\n",
       "  'work',\n",
       "  'facebook',\n",
       "  'facebook',\n",
       "  'note',\n",
       "  'neil',\n",
       "  'degrass',\n",
       "  'tyson',\n",
       "  'scienc',\n",
       "  'work',\n",
       "  '10153892230401613'],\n",
       " ['anybodi', 'still', 'unsur', 'object', 'truth', 'huff', '2169ara'],\n",
       " ['technic',\n",
       "  'zillion',\n",
       "  'pomegran',\n",
       "  'seed',\n",
       "  'would',\n",
       "  'need',\n",
       "  'seedless',\n",
       "  'easi',\n",
       "  'invent',\n",
       "  'lap',\n",
       "  'dog'],\n",
       " ['seedless',\n",
       "  'grape',\n",
       "  'seedless',\n",
       "  'orang',\n",
       "  'seedless',\n",
       "  'watermelon',\n",
       "  'good',\n",
       "  'vote',\n",
       "  'next',\n",
       "  'fruit',\n",
       "  'invent',\n",
       "  'seedless',\n",
       "  'pomegran'],\n",
       " ['curiou',\n",
       "  'like',\n",
       "  'bond',\n",
       "  'one',\n",
       "  'anoth',\n",
       "  'base',\n",
       "  'believ',\n",
       "  'true',\n",
       "  'rather',\n",
       "  'object',\n",
       "  'true'],\n",
       " ['post',\n",
       "  'startalkradio',\n",
       "  'scienc',\n",
       "  'social',\n",
       "  'justic',\n",
       "  'thedavidcrosbi',\n",
       "  'itunespodcast',\n",
       "  '1onxqrr'],\n",
       " ['lotteri',\n",
       "  'fund',\n",
       "  'state',\n",
       "  'educ',\n",
       "  'budget',\n",
       "  'best',\n",
       "  'way',\n",
       "  'sustain',\n",
       "  'teach',\n",
       "  'probabl',\n",
       "  'statist',\n",
       "  'school'],\n",
       " ['case',\n",
       "  'anybodi',\n",
       "  'wonder',\n",
       "  'astrophysicist',\n",
       "  'highest',\n",
       "  'follow',\n",
       "  'jimmyfallonp',\n",
       "  'ehacfmr7hr'],\n",
       " ['cinemat',\n",
       "  'hypothesi',\n",
       "  'film',\n",
       "  'festiv',\n",
       "  'movi',\n",
       "  'win',\n",
       "  'fewer',\n",
       "  'gun',\n",
       "  'chase',\n",
       "  'scene',\n",
       "  'explos',\n",
       "  'contain'],\n",
       " ['wonder',\n",
       "  'form',\n",
       "  'creativ',\n",
       "  'gener',\n",
       "  'space',\n",
       "  'odditi',\n",
       "  'fall',\n",
       "  'earth',\n",
       "  'rip',\n",
       "  'davidbowi',\n",
       "  '1947',\n",
       "  '2016'],\n",
       " ['neiltyson', 'crude', 'ga', 'someth', 'els', 'entir'],\n",
       " ['fyi',\n",
       "  'crude',\n",
       "  'oil',\n",
       "  'natur',\n",
       "  'natur',\n",
       "  'ga',\n",
       "  'deriv',\n",
       "  'buri',\n",
       "  'long',\n",
       "  'dead',\n",
       "  'decompos',\n",
       "  'plant',\n",
       "  'anim'],\n",
       " ['crisreno', 'abl', 'see', 'brazil', 'need', 'dawn'],\n",
       " ['wednesday',\n",
       "  'morn',\n",
       "  'earli',\n",
       "  'rise',\n",
       "  'look',\n",
       "  'east',\n",
       "  'crescent',\n",
       "  'moon',\n",
       "  'join',\n",
       "  'venu',\n",
       "  'saturn',\n",
       "  'afloat',\n",
       "  'dawn',\n",
       "  'sky'],\n",
       " ['space',\n",
       "  'alien',\n",
       "  'would',\n",
       "  'sure',\n",
       "  'think',\n",
       "  'odd',\n",
       "  'one',\n",
       "  'way',\n",
       "  'human',\n",
       "  'express',\n",
       "  'affect',\n",
       "  'simultan',\n",
       "  'exchang',\n",
       "  'saliva']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.007*\"peopl\" + 0.006*\"wonder\" + 0.006*\"world\"'), (1, '0.017*\"day\" + 0.009*\"earth\" + 0.007*\"year\"'), (2, '0.019*\"startalkradio\" + 0.018*\"post\" + 0.017*\"itunespodcast\"')]\n"
     ]
    }
   ],
   "source": [
    "# learn a topic model for the tweets\n",
    "tweet_topics = 3\n",
    "tweet_model = gensim.models.ldamodel.LdaModel(tweet_corpus, num_topics=tweet_topics, id2word = tweet_dict, passes=20)\n",
    "print(tweet_model.print_topics(tweet_topics, num_words=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/_pytest/fixtures.py:847: DeprecationWarning: The `convert` argument is deprecated in favor of `converter`.  It will be removed after 2019/01.\n",
      "  params = attr.ib(convert=attr.converters.optional(tuple))\n",
      "/usr/local/lib/python3.6/site-packages/_pytest/fixtures.py:849: DeprecationWarning: The `convert` argument is deprecated in favor of `converter`.  It will be removed after 2019/01.\n",
      "  ids = attr.ib(default=None, convert=_ensure_immutable_ids)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'topics'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   2027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2028\u001b[0;31m             \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2029\u001b[0m             \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'topics'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d9edd52d897a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# assign topic labels to each tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"topics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1886\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   2033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m             \u001b[0;31m# set using a non-recursive method & reset the cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2035\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2036\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    359\u001b[0m                         new_indexer = convert_from_missing_indexer_tuple(\n\u001b[1;32m    360\u001b[0m                             indexer, self.obj.axes)\n\u001b[0;32m--> 361\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    581\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                         raise ValueError('Must have equal len keys and value '\n\u001b[0m\u001b[1;32m    584\u001b[0m                                          'when setting with an ndarray')\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "# assign topic labels to each tweet\n",
    "for i in range(0, len(tweet_texts)):\n",
    "    df.at[i,\"topics\"] = tweet_model[tweet_dict.doc2bow(tweet_texts[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0][\"tweet-text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_vis = pyLDAvis.gensim.prepare(tweet_model, tweet_corpus, tweet_dict)\n",
    "pyLDAvis.display(tweet_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise\n",
    "Try building a topic model using tweets from all six files together. \n",
    "\n",
    "Can you fit a set of topics that captures the variation in topics across the different users?\n",
    "\n",
    "What parameters did you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
